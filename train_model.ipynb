{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755c5127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5455c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ColorJitter(brightness=0.2,\n",
    "                           contrast=0.2,\n",
    "                           saturation=0.2,\n",
    "                           hue=0.1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0075ec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö  20 classes detected: {0: '00175_Animalia_Arthropoda_Insecta_Blattodea_Blaberidae_Aptera_fusca', 1: '00176_Animalia_Arthropoda_Insecta_Blattodea_Blaberidae_Panchlora_nivea', 2: '00177_Animalia_Arthropoda_Insecta_Blattodea_Blaberidae_Pycnoscelus_surinamensis', 3: '00178_Animalia_Arthropoda_Insecta_Blattodea_Blattidae_Blatta_orientalis', 4: '00179_Animalia_Arthropoda_Insecta_Blattodea_Blattidae_Periplaneta_americana', 5: '00180_Animalia_Arthropoda_Insecta_Blattodea_Blattidae_Periplaneta_australasiae', 6: '00181_Animalia_Arthropoda_Insecta_Blattodea_Blattidae_Periplaneta_fuliginosa', 7: '00182_Animalia_Arthropoda_Insecta_Blattodea_Ectobiidae_Pseudomops_septentrionalis', 8: '00443_Animalia_Arthropoda_Insecta_Diptera_Culicidae_Aedes_aegypti', 9: '00444_Animalia_Arthropoda_Insecta_Diptera_Culicidae_Aedes_albopictus', 10: '00445_Animalia_Arthropoda_Insecta_Diptera_Culicidae_Aedes_vexans', 11: '00446_Animalia_Arthropoda_Insecta_Diptera_Culicidae_Culex_quinquefasciatus', 12: '00447_Animalia_Arthropoda_Insecta_Diptera_Culicidae_Psorophora_ciliata', 13: '00449_Animalia_Arthropoda_Insecta_Diptera_Muscidae_Mesembrina_meridiana', 14: '00450_Animalia_Arthropoda_Insecta_Diptera_Muscidae_Musca_domestica', 15: '00451_Animalia_Arthropoda_Insecta_Diptera_Muscidae_Stomoxys_calcitrans', 16: '04813_Animalia_Chordata_Mammalia_Rodentia_Muridae_Mus_musculus', 17: '04814_Animalia_Chordata_Mammalia_Rodentia_Muridae_Rattus_norvegicus', 18: '04815_Animalia_Chordata_Mammalia_Rodentia_Muridae_Rattus_rattus', 19: '04816_Animalia_Chordata_Mammalia_Rodentia_Muridae_Rhabdomys_pumilio'}\n",
      "Batch tensor shape: torch.Size([64, 3, 224, 224])\n",
      "Labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "root_dir   = Path(\"dataset\")\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "\n",
    "# Datasets\n",
    "train_ds = datasets.ImageFolder(root_dir / \"train_extracted\",\n",
    "                                transform=train_transforms)\n",
    "val_ds   = datasets.ImageFolder(root_dir / \"val_extracted\",\n",
    "                                transform=val_test_transforms)\n",
    "# test_ds  = datasets.ImageFolder(root_dir / \"test_extracted\",\n",
    "#                                 transform=val_test_transforms)\n",
    "\n",
    "# DataLoaders\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                      num_workers=num_workers, pin_memory=True, drop_last=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
    "                      num_workers=num_workers, pin_memory=True)\n",
    "# test_dl  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False,\n",
    "#                       num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "# Quick sanity check\n",
    "idx_to_class = {v: k for k, v in train_ds.class_to_idx.items()}\n",
    "print(f\"{len(idx_to_class)} classes detected:\", idx_to_class)\n",
    "\n",
    "imgs, labels = next(iter(train_dl))\n",
    "print(\"Batch tensor shape:\", imgs.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdae3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìí  Cell 4 ‚Äî ConvNeXt-Tiny with local IN-12k weights (head stripped)\n",
    "\n",
    "import torch, timm, pathlib, re, torch.nn as nn\n",
    "from torchsummary import summary                # optional: pip install torchsummary\n",
    "\n",
    "# --------------------------------------------------------------- paths & config\n",
    "ckpt_path   = pathlib.Path(\"convnext_tiny_in12k.pth\")   # local file you downloaded\n",
    "DEVICE      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_classes = len(idx_to_class)                         # from Cell 3\n",
    "IMG_SIZE    = 224\n",
    "\n",
    "# --------------------------------------------------------------- 1Ô∏è‚É£  build full model (20-class head)\n",
    "model = timm.create_model(\n",
    "    \"convnext_tiny.in12k\",\n",
    "    pretrained=False,          # ‚Üê don't hit the Internet\n",
    "    num_classes=num_classes\n",
    ").to(DEVICE)\n",
    "\n",
    "# --------------------------------------------------------------- 2Ô∏è‚É£  load backbone weights\n",
    "raw = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "state_dict = raw[\"model\"] if isinstance(raw, dict) and \"model\" in raw else raw\n",
    "\n",
    "# strip 'module.' prefix (DDP) and *discard* the old 11 821-class head\n",
    "clean_sd = {\n",
    "    re.sub(r'^module\\.', '', k): v\n",
    "    for k, v in state_dict.items()\n",
    "    if not k.startswith(\"head.\")          # <-- drop obsolete classifier weights\n",
    "}\n",
    "\n",
    "missing, unexpected = model.load_state_dict(clean_sd, strict=False)\n",
    "print(f\"‚úÖ  Backbone loaded ‚Äî skipped {len(unexpected)} head weights \"\n",
    "      f\"‚Ä¢ missing keys (new 20-way head): {len(missing)}\")\n",
    "\n",
    "# --------------------------------------------------------------- 3Ô∏è‚É£  sanity forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    imgs, _ = next(iter(train_dl))        # from Cell 3\n",
    "    logits = model(imgs.to(DEVICE))\n",
    "    print(\"Logits shape:\", logits.shape)  # expect [batch, 20]\n",
    "\n",
    "# --------------------------------------------------------------- 4Ô∏è‚É£  (optional) layer table\n",
    "try:\n",
    "    summary(model, input_size=(3, IMG_SIZE, IMG_SIZE))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468dd57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìí  Cell 5 ‚Äî Train / validate ConvNeXt-Tiny\n",
    "import torch, time, math\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# ---------------------- hyper-parameters -----------------------------\n",
    "EPOCHS                = 10\n",
    "FREEZE_BACKBONE_EPOCH = 1          # unfreeze after this many epochs\n",
    "LR_HEAD               = 1e-3       # while backbone frozen\n",
    "LR_FULL               = 3e-4       # after unfreeze\n",
    "WEIGHT_DECAY          = 1e-2\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# head params only (backbone frozen) ----------------\n",
    "head_params = [p for n,p in model.named_parameters() if n.startswith(\"head.\")]\n",
    "optimizer   = torch.optim.AdamW(head_params, lr=LR_HEAD, weight_decay=WEIGHT_DECAY)\n",
    "scheduler   = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "scaler = GradScaler()              # AMP\n",
    "\n",
    "# ---------------------- helper to toggle backbone grads --------------\n",
    "def set_backbone_trainable(flag: bool):\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(\"head.\"):\n",
    "            param.requires_grad = flag\n",
    "\n",
    "set_backbone_trainable(False)      # freeze initially\n",
    "\n",
    "# ---------------------- training loop --------------------------------\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    running_loss, correct, seen = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in train_dl:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():                           # mixed precision\n",
    "            logits = model(images)\n",
    "            loss   = criterion(logits, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        correct      += (logits.argmax(1) == labels).sum().item()\n",
    "        seen         += images.size(0)\n",
    "\n",
    "    train_loss = running_loss / seen\n",
    "    train_acc  = correct / seen\n",
    "\n",
    "    # ------------- validation -------------\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_seen = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_dl:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            with autocast():\n",
    "                logits = model(images)\n",
    "                loss   = criterion(logits, labels)\n",
    "\n",
    "            val_loss   += loss.item() * images.size(0)\n",
    "            val_correct += (logits.argmax(1) == labels).sum().item()\n",
    "            val_seen   += images.size(0)\n",
    "\n",
    "    val_loss /= val_seen\n",
    "    val_acc  = val_correct / val_seen\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"[{epoch:02}/{EPOCHS}] \"\n",
    "          f\"train {train_loss:.4f} / {train_acc:.2%} ‚îÇ \"\n",
    "          f\"val {val_loss:.4f} / {val_acc:.2%} ‚îÇ \"\n",
    "          f\"lr {optimizer.param_groups[0]['lr']:.2e} ‚îÇ \"\n",
    "          f\"{(time.time()-t0):.1f}s\")\n",
    "\n",
    "    # --------- unfreeze backbone after first epoch ----------\n",
    "    if epoch == FREEZE_BACKBONE_EPOCH:\n",
    "        print(\"üü¢ Unfreezing backbone & switching to lower LR.\")\n",
    "        set_backbone_trainable(True)\n",
    "        # re-build optimizer to include *all* parameters\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=LR_FULL,\n",
    "                                      weight_decay=WEIGHT_DECAY)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                        optimizer, T_max=EPOCHS - epoch)\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
